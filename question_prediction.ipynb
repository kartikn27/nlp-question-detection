{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 1: Using basic Parse tree created using Stanford's CORE NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "class isQuestionBasic():\n",
    "    \n",
    "    # Init Constructor\n",
    "    # Initialize StanfordCore NLP local instance on port 9000\n",
    "    def __init__(self):\n",
    "        self.nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "        \n",
    "    # Input: Sentence to be predicted\n",
    "    # Processing: 1. Uses Stanfors NLP's 'annotate' method to create Parse Tree\n",
    "    # 2. Checks for occurence of 'SQ' or 'SBARQ' in the parse tree\n",
    "    # Return: 1 - If sentence is question | 0 - If sentence is not a question\n",
    "    def isQuestion(self, sentence):\n",
    "        if '?' in sentence:\n",
    "            return 1\n",
    "        output = self.nlp.annotate(sentence, properties={\n",
    "            'annotators': 'parse',\n",
    "            'outputFormat': 'json',\n",
    "            'timeout': 1000,\n",
    "        })\n",
    "\n",
    "        if ('SQ' or 'SBARQ') in output['sentences'][0][\"parse\"]:\n",
    "            return 1    \n",
    "        else:\n",
    "            return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "isQuestionBasic_obj = isQuestionBasic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('queries-10k-txt', sep='\\t')\n",
    "df['is_question'] = df['QUERY'].apply(isQuestionBasic_obj.isQuestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9332\n",
       "1     668\n",
       "Name: is_question, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_question'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 2: DETECTION USING NLTK CLASSIFICATION TECHNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('nps_chat')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk.corpus\n",
    "from nltk.corpus import nps_chat\n",
    "import pandas as pd\n",
    "\n",
    "class IsQuestion():\n",
    "    \n",
    "    # Init constructor\n",
    "    def __init__(self):\n",
    "        posts = self.__get_posts()\n",
    "        feature_set = self.__get_feature_set(posts)\n",
    "        self.classifier = self.__perform_classification(feature_set)\n",
    "        \n",
    "    # Method (Private): __get_posts\n",
    "    # Input: None\n",
    "    # Output: Posts (Text) from NLTK's nps_chat package\n",
    "    def __get_posts(self):\n",
    "        return nltk.corpus.nps_chat.xml_posts()\n",
    "    \n",
    "    # Method (Private): __get_feature_set\n",
    "    # Input: Posts from NLTK's nps_chat package\n",
    "    # Processing: 1. preserve alpha numeric characters, whitespace, apostrophe\n",
    "    # 2. Tokenize sentences using NLTK's word_tokenize\n",
    "    # 3. Create a dictionary of list of tuples for each post where tuples index 0 is the dictionary of words occuring in the sentence and index 1 is the class as received from nps_chat package \n",
    "    # Return: List of tuples for each post\n",
    "    def __get_feature_set(self, posts):\n",
    "        feature_list = []\n",
    "        for post in posts:\n",
    "            post_text = post.text            \n",
    "            features = {}\n",
    "            words = nltk.word_tokenize(post_text)\n",
    "            for word in words:\n",
    "                features['contains({})'.format(word.lower())] = True\n",
    "            feature_list.append((features, post.get('class')))\n",
    "        return feature_list\n",
    "    \n",
    "    # Method (Private): __perform_classification\n",
    "    # Input: List of tuples for each post\n",
    "    # Processing: 1. Divide data into 80% training and 10% testing sets\n",
    "    # 2. Use NLTK's Multinomial Naive Bayes to perform classifcation\n",
    "    # 3. Print the Accuracy of the model\n",
    "    # Return: Classifier object\n",
    "    def __perform_classification(self, feature_set):\n",
    "        training_size = int(len(feature_set) * 0.1)\n",
    "        train_set, test_set = feature_set[training_size:], feature_set[:training_size]\n",
    "        classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        print('Accuracy is : ', nltk.classify.accuracy(classifier, test_set))\n",
    "        return classifier\n",
    "        \n",
    "    # Method (private): __get_question_words_set\n",
    "    # Input: None\n",
    "    # Return: Set of commonly occuring words in questions\n",
    "    def __get_question_words_set(self):\n",
    "        question_word_list = ['what', 'where', 'when','how','why','did','do','does','have','has','am','is','are','can','could','may','would','will','should'\n",
    "\"didn't\",\"doesn't\",\"haven't\",\"isn't\",\"aren't\",\"can't\",\"couldn't\",\"wouldn't\",\"won't\",\"shouldn't\",'?']\n",
    "        return set(question_word_list)        \n",
    "    \n",
    "    # Method (Public): predict_question\n",
    "    # Input: Sentence to be predicted\n",
    "    # Return: 1 - If sentence is question | 0 - If sentence is not question\n",
    "    def predict_question(self, text):\n",
    "        words = nltk.word_tokenize(text.lower())        \n",
    "        if self.__get_question_words_set().intersection(words) == False:\n",
    "            return 0\n",
    "        if '?' in text:\n",
    "            return 1\n",
    "        \n",
    "        features = {}\n",
    "        for word in words:\n",
    "            features['contains({})'.format(word.lower())] = True            \n",
    "        \n",
    "        prediction_result = self.classifier.classify(features)\n",
    "        if prediction_result == 'whQuestion' or prediction_result == 'ynQuestion':\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    # Method (Public): predict_question_type\n",
    "    # Input: Sentence to be predicted\n",
    "    # Return: 'WH' - If question is WH question | 'YN' - If sentence is Yes/NO question | 'unknown' - If unknown question type\n",
    "    def predict_question_type(self, text):\n",
    "        words = nltk.word_tokenize(text.lower())                \n",
    "        features = {}\n",
    "        for word in words:\n",
    "            features['contains({})'.format(word.lower())] = True            \n",
    "        \n",
    "        prediction_result = self.classifier.classify(features)\n",
    "        if prediction_result == 'whQuestion':\n",
    "            return 'WH'\n",
    "        elif prediction_result == 'ynQuestion':\n",
    "            return 'YN'\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  0.6685606060606061\n"
     ]
    }
   ],
   "source": [
    "isQ = IsQuestion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sample sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isQ.predict_question('what is this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WH'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isQ.predict_question_type('what is this')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('queries-10k-txt', sep='\\t')\n",
    "df_1['is_question'] = df_1['QUERY'].apply(isQ.predict_question)\n",
    "df_1['question_type'] = df_1[df_1['is_question'] == 1]['QUERY'].apply(isQ.predict_question_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8799\n",
       "1    1201\n",
       "Name: is_question, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['is_question'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WH    944\n",
       "YN    257\n",
       "Name: question_type, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['question_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 3: DETECTION USING ADVANCED CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class IsQuestionAdvanced():\n",
    "    \n",
    "    # Init constructor\n",
    "    # Input: Type of classification: 'MNB' - Multinomial Naive Bayes | 'SVM' - Support Vector Machine\n",
    "    def __init__(self, classification_type):\n",
    "        self.classification_type = classification_type\n",
    "        df = self.__get_data()\n",
    "        df = self.__clean_data(df)\n",
    "        df = self.__label_encode(df)\n",
    "        vectorizer_classifier = self.__create_classifier(df, self.classification_type)\n",
    "        if vectorizer_classifier is not None:\n",
    "            self.vectorizer = vectorizer_classifier['vectorizer']\n",
    "            self.classifier = vectorizer_classifier['classifier']        \n",
    "        \n",
    "    # Method (Private):  __clean_data\n",
    "    # Input: Raw input dataframe\n",
    "    # Processing: 1. Rename column \n",
    "    # 2. lowercase text\n",
    "    # 3. preserve alpha numeric characters, whitespace, apostrophe\n",
    "    # 4. filter dataframe with questiin types - what, who, when, affirmation, unknown\n",
    "    # Return: Processed filtered dataframe\n",
    "    def __clean_data(self, df):\n",
    "        df.rename(columns={0: 'text', 1: 'type'}, inplace=True)\n",
    "        df['type'] = df['type'].str.strip()\n",
    "        df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "        df['text'] = df['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s\\']','',x)))\n",
    "        return df[(df['type'] == 'what') | (df['type'] == 'who') | (df['type'] == 'when') | (df['type'] == 'unknown') | (df['type'] == 'affirmation')]\n",
    "    \n",
    "\n",
    "    # Method (Private): __label_encode\n",
    "    # Input: Processed dataframe\n",
    "    # Processing: Use label encoding to convert text label to integer label and add it to a new column\n",
    "    # Return: Processed dataframe with label encoding column\n",
    "    def __label_encode(self, df):\n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        self.le.fit(df['type'])\n",
    "        df['label'] = list(self.le.transform(df['type']))\n",
    "        return df\n",
    "    \n",
    "    # Method (Private): __create_classifier\n",
    "    # Input: 1. Processed dataframe 2. Type of classification\n",
    "    # Processing: 1. Perform TFIDF Vectorization\n",
    "    # 2. Appy fit_tranform using TFIDF on text column\n",
    "    # 3. Split data into 70% training and 30% testing\n",
    "    # 4. Perform Multinomial Naive Bayes OR SVM classifcation based on input provided\n",
    "    # 5. Peform prediction for both classification techniques on test data\n",
    "    # 6. Show confusion matrix and accuracy\n",
    "    # Return: Dict - TFIDF Vetctorizer, Classifier    \n",
    "    def __create_classifier(self, df, classification_type):\n",
    "        v = TfidfVectorizer(analyzer='word',lowercase=True)\n",
    "        X = v.fit_transform(df['text'])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, df['label'], test_size=0.30)\n",
    "        if classification_type == 'MNB':\n",
    "            clf = MultinomialNB()\n",
    "            clf.fit(X_train,y_train)\n",
    "            preds = clf.predict(X_test)\n",
    "            print(classification_report(preds,y_test))\n",
    "            print('Accuracy is: ', clf.score(X_test,y_test))\n",
    "            return {'vectorizer': v, 'classifier': clf}\n",
    "        elif classification_type == 'SVM':\n",
    "            clf_svm = SVC(kernel='linear')\n",
    "            clf_svm.fit(X_train,y_train)\n",
    "            preds = clf_svm.predict(X_test)\n",
    "            preds = print(classification_report(preds,y_test))\n",
    "            print('Accuracy is: ', clf_svm.score(X_test,y_test))\n",
    "            return {'vectorizer': v, 'classifier': clf_svm}\n",
    "        else:\n",
    "            print(\"Wrong classification type: \\n Type 'MNB' - Multinomial Naive Bayes \\n Type 'SVM' - Support Vector Machine\")    \n",
    "            \n",
    "\n",
    "    # Method (Private): __get_data\n",
    "    # Processing: Get the sample input data used to create traning, test, vectorizer, classifier data\n",
    "    # Return: Pandas dataframe\n",
    "    def __get_data(self):\n",
    "        return pd.read_csv('sample.txt', sep=',,,', header=None)\n",
    "    \n",
    "    # Method (Public): predict\n",
    "    # Input: An unknown new sentence\n",
    "    # Return: Prediction - Typpe of question 'what', 'when', 'who'\n",
    "    def predict(self, sentence):\n",
    "        ex = self.vectorizer.transform([sentence])\n",
    "        return list(self.le.inverse_transform(self.classifier.predict(ex)))[0]                \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:86: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        31\n",
      "           1       0.96      0.95      0.95        76\n",
      "           2       0.97      0.97      0.97       196\n",
      "           3       0.90      0.84      0.87        32\n",
      "           4       0.99      0.99      0.99       110\n",
      "\n",
      "    accuracy                           0.96       445\n",
      "   macro avg       0.94      0.95      0.95       445\n",
      "weighted avg       0.96      0.96      0.96       445\n",
      "\n",
      "Accuracy is:  0.9640449438202248\n"
     ]
    }
   ],
   "source": [
    "# Model created using SVM\n",
    "obj = IsQuestionAdvanced('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'when'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.predict('what time are you going there')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on questions classified by method 1 <br> df is created by method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df[df['is_question'] == 1].copy()\n",
    "df_2['question_type'] = df_2['QUERY'].apply(obj.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what       405\n",
       "unknown    193\n",
       "who         52\n",
       "when        18\n",
       "Name: question_type, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2['question_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on questions classified by method 2 <br> df_1 is created by method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_1[df_1['is_question'] == 1].copy()\n",
    "df_3['question_type'] = df_3['QUERY'].apply(obj.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown        593\n",
       "what           544\n",
       "who             50\n",
       "when             8\n",
       "affirmation      6\n",
       "Name: question_type, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3['question_type'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
